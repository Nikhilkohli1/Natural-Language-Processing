{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_score_mixed</th>\n",
       "      <th>amazon_score_negative</th>\n",
       "      <th>amazon_score_neutral</th>\n",
       "      <th>amazon_score_positive</th>\n",
       "      <th>amazon_sentiments_label</th>\n",
       "      <th>azure_api_label</th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_label</th>\n",
       "      <th>google_sentiment_magnitude</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>ibm_sentiments_label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.247337</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Thank you. Good afternoon, everyone. And welco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.104133</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>As we look past Q1, we expect the channel inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.980631</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>And your last question comes from the line of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.953385</td>\n",
       "      <td>0.034877</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>On the China gaming weakness, is it the slower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>positive</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>I don't know that we could tear that apart, te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazon_score_mixed  amazon_score_negative  amazon_score_neutral  \\\n",
       "0            0.001549               0.000533              0.750581   \n",
       "1            0.009229               0.006072              0.880566   \n",
       "2            0.000831               0.008268              0.980631   \n",
       "3            0.011638               0.953385              0.034877   \n",
       "4            0.014957               0.000221              0.007328   \n",
       "\n",
       "   amazon_score_positive amazon_sentiments_label azure_api_label  \\\n",
       "0               0.247337                 neutral        positive   \n",
       "1               0.104133                 neutral         neutral   \n",
       "2               0.010270                 neutral         neutral   \n",
       "3               0.000099                negative         neutral   \n",
       "4               0.977495                positive        positive   \n",
       "\n",
       "   azure_api_score google_sentiment_label  google_sentiment_magnitude  \\\n",
       "0         0.978328               positive                         1.1   \n",
       "1         0.500000               positive                         1.4   \n",
       "2         0.500000                neutral                         0.0   \n",
       "3         0.500000               negative                         1.2   \n",
       "4         0.905933               positive                         7.9   \n",
       "\n",
       "   google_sentiment_socre  ibm_score ibm_sentiments_label sentiment  \\\n",
       "0                     0.2   0.816136             positive  positive   \n",
       "1                     0.2   0.558518             positive  positive   \n",
       "2                     0.0   0.000000              neutral   neutral   \n",
       "3                    -0.3  -0.598559             negative  negative   \n",
       "4                     0.5   0.790615             positive  negative   \n",
       "\n",
       "                                                text  \n",
       "0  Thank you. Good afternoon, everyone. And welco...  \n",
       "1  As we look past Q1, we expect the channel inve...  \n",
       "2  And your last question comes from the line of ...  \n",
       "3  On the China gaming weakness, is it the slower...  \n",
       "4  I don't know that we could tear that apart, te...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('final_label_json_data.json') as f:\n",
    "    sentiment = pd.DataFrame(json.load(f))\n",
    "    \n",
    "sentiment.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment['amazon_sentiment_score'] = sentiment[[\"amazon_score_negative\",\"amazon_score_neutral\",\"amazon_score_positive\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazon_score_mixed</th>\n",
       "      <th>amazon_score_negative</th>\n",
       "      <th>amazon_score_neutral</th>\n",
       "      <th>amazon_score_positive</th>\n",
       "      <th>amazon_sentiments_label</th>\n",
       "      <th>azure_api_label</th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_label</th>\n",
       "      <th>google_sentiment_magnitude</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>ibm_sentiments_label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>0.247337</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Thank you. Good afternoon, everyone. And welco...</td>\n",
       "      <td>0.750581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>0.104133</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>As we look past Q1, we expect the channel inve...</td>\n",
       "      <td>0.880566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.980631</td>\n",
       "      <td>0.010270</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>And your last question comes from the line of ...</td>\n",
       "      <td>0.980631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.953385</td>\n",
       "      <td>0.034877</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>On the China gaming weakness, is it the slower...</td>\n",
       "      <td>0.953385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014957</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.007328</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>positive</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>I don't know that we could tear that apart, te...</td>\n",
       "      <td>0.977495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014018</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.291906</td>\n",
       "      <td>0.674756</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.904133</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Thank you. I'll now turn the call back over to...</td>\n",
       "      <td>0.674756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.451327</td>\n",
       "      <td>0.037996</td>\n",
       "      <td>0.373289</td>\n",
       "      <td>0.137388</td>\n",
       "      <td>mixed</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.832192</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.574769</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>2018 was a record year but it was a disappoint...</td>\n",
       "      <td>0.373289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004365</td>\n",
       "      <td>0.080391</td>\n",
       "      <td>0.883574</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.586947</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>And this concludes today's conference call. Yo...</td>\n",
       "      <td>0.883574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.717327</td>\n",
       "      <td>0.281674</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.884016</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>In addition, we announced a record of 40 plus ...</td>\n",
       "      <td>0.717327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000758</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.637107</td>\n",
       "      <td>0.362118</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.748680</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>We're also pleased to see growing momentum in ...</td>\n",
       "      <td>0.637107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.051867</td>\n",
       "      <td>0.945111</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.952201</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.875206</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Pairing DLSS with ray tracing can provide comp...</td>\n",
       "      <td>0.945111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014933</td>\n",
       "      <td>0.287314</td>\n",
       "      <td>0.694258</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.558735</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moving to data center. Revenue was $679 millio...</td>\n",
       "      <td>0.694258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028350</td>\n",
       "      <td>0.082266</td>\n",
       "      <td>0.638542</td>\n",
       "      <td>0.250842</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.569009</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>In addition, hyperscale and cloud purchases de...</td>\n",
       "      <td>0.638542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.990345</td>\n",
       "      <td>0.009309</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.775907</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>For example, we recently announced RAPIDS, our...</td>\n",
       "      <td>0.990345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.029805</td>\n",
       "      <td>0.006176</td>\n",
       "      <td>0.890847</td>\n",
       "      <td>0.073172</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564156</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Our visibility remains low in the current caut...</td>\n",
       "      <td>0.890847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.968123</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.915934</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>We have also strengthened our product portfoli...</td>\n",
       "      <td>0.968123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.828256</td>\n",
       "      <td>0.169730</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.633038</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Moving to pro visualization, revenue reached $...</td>\n",
       "      <td>0.828256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.399467</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.800259</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.677819</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>The webcast will be available for replay until...</td>\n",
       "      <td>0.595677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.942365</td>\n",
       "      <td>0.055135</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732119</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Finally, turning to automotive. Q4 revenue was...</td>\n",
       "      <td>0.942365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.996916</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.681920</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>To deliver these capabilities, DRIVE AutoPilot...</td>\n",
       "      <td>0.996916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.990362</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577718</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Mercedes-Benz has also chosen NVIDIA for its n...</td>\n",
       "      <td>0.990362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.993256</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.287068</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>Moving to the rest of the P&amp;L and balance shee...</td>\n",
       "      <td>0.993256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.025572</td>\n",
       "      <td>0.316995</td>\n",
       "      <td>0.651127</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.186991</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.844607</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>With that, let me turn to the outlook for the ...</td>\n",
       "      <td>0.651127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.026225</td>\n",
       "      <td>0.943055</td>\n",
       "      <td>0.018790</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.355513</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>For fiscal 2020, we expect Q1 to mark the bott...</td>\n",
       "      <td>0.943055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.047803</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.662070</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>In closing, I'd like to highlight upcoming eve...</td>\n",
       "      <td>0.943089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.074492</td>\n",
       "      <td>0.231137</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>0.313381</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.523252</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>I had two questions. First, Colette, you talke...</td>\n",
       "      <td>0.380990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.059969</td>\n",
       "      <td>0.172489</td>\n",
       "      <td>0.718136</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.229010</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.309086</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>When we launched the 2070 and 2080, it was the...</td>\n",
       "      <td>0.718136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.013141</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.090313</td>\n",
       "      <td>0.895706</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.889206</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>And I think that right out of the box, it deli...</td>\n",
       "      <td>0.895706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.004911</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.939778</td>\n",
       "      <td>0.053595</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.346326</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>During this call, we may make forward-looking ...</td>\n",
       "      <td>0.939778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.020755</td>\n",
       "      <td>0.209473</td>\n",
       "      <td>0.759121</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.385726</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>So Toshiya to answer your second question rega...</td>\n",
       "      <td>0.759121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.113443</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744958</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Turning to Page 13 on Capital. Our Common Equi...</td>\n",
       "      <td>0.864094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.245939</td>\n",
       "      <td>0.690269</td>\n",
       "      <td>0.048437</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607678</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>For the full year, we repurchased 13.9 million...</td>\n",
       "      <td>0.690269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>0.007706</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.956241</td>\n",
       "      <td>0.029955</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290116</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Turning to balance sheet and liquidity on Page...</td>\n",
       "      <td>0.956241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.823326</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.985956</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Before taking questions, a few closing thought...</td>\n",
       "      <td>0.923570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.190050</td>\n",
       "      <td>0.729713</td>\n",
       "      <td>0.025485</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.832761</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.837670</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Lastly, the management team is motivated by th...</td>\n",
       "      <td>0.729713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>0.046867</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.778988</td>\n",
       "      <td>0.136486</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.853107</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.943123</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>With that, thanks again for dialing in, and we...</td>\n",
       "      <td>0.778988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Question-and-Answer Session</td>\n",
       "      <td>0.981933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>0.015355</td>\n",
       "      <td>0.245939</td>\n",
       "      <td>0.690269</td>\n",
       "      <td>0.048437</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.690269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>0.014219</td>\n",
       "      <td>0.078054</td>\n",
       "      <td>0.875139</td>\n",
       "      <td>0.032589</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Mayo - Wells Fargo Securities</td>\n",
       "      <td>0.875139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[Operator Instructions]. Your first question i...</td>\n",
       "      <td>0.923570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>0.070567</td>\n",
       "      <td>0.417806</td>\n",
       "      <td>0.470117</td>\n",
       "      <td>0.041511</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Glenn Schorr</td>\n",
       "      <td>0.470117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>0.062484</td>\n",
       "      <td>0.152350</td>\n",
       "      <td>0.674526</td>\n",
       "      <td>0.110639</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.488886</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>And I want to talk about I&amp;L. And it's a combo...</td>\n",
       "      <td>0.674526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>0.939878</td>\n",
       "      <td>0.034276</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Stephen Scherr</td>\n",
       "      <td>0.939878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.001839</td>\n",
       "      <td>0.022030</td>\n",
       "      <td>0.966246</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.801530</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Sure. Thanks, Glenn. I appreciate the question...</td>\n",
       "      <td>0.966246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>0.011507</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637414</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>And together, those five names contributed to ...</td>\n",
       "      <td>0.980603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.064148</td>\n",
       "      <td>0.916375</td>\n",
       "      <td>0.004275</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Glenn Schorr</td>\n",
       "      <td>0.916375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.898174</td>\n",
       "      <td>positive</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555948</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Okay. That's all very helpful, and it sets up ...</td>\n",
       "      <td>0.923570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>0.003587</td>\n",
       "      <td>0.069386</td>\n",
       "      <td>0.915397</td>\n",
       "      <td>0.011630</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>David Solomon</td>\n",
       "      <td>0.915397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.052466</td>\n",
       "      <td>0.630312</td>\n",
       "      <td>0.309089</td>\n",
       "      <td>0.008132</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.759198</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>So I'll start, Glenn, and I'll just comment. O...</td>\n",
       "      <td>0.630312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>0.011507</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Chinedu Bolu - Sanford C. Bernstein &amp; Co.</td>\n",
       "      <td>0.980603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.217418</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>0.243894</td>\n",
       "      <td>0.536106</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Operator</td>\n",
       "      <td>0.536106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Your next question is from the line of Michael...</td>\n",
       "      <td>0.923570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.067419</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.266760</td>\n",
       "      <td>0.636460</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.748757</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Carrier</td>\n",
       "      <td>0.636460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.021840</td>\n",
       "      <td>0.939878</td>\n",
       "      <td>0.034276</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.357957</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>Stephen, maybe one more, just on the I&amp;L busin...</td>\n",
       "      <td>0.939878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Stephen Scherr</td>\n",
       "      <td>0.929166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>positive</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.767542</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>Sure. Thanks for the question. I think it's di...</td>\n",
       "      <td>0.971907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>0.037598</td>\n",
       "      <td>0.040455</td>\n",
       "      <td>0.734124</td>\n",
       "      <td>0.187823</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274780</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>And that has thrown up, as I said in my commen...</td>\n",
       "      <td>0.734124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.008180</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>0.065307</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.748757</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Michael Carrier</td>\n",
       "      <td>0.923570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.007209</td>\n",
       "      <td>0.981843</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.420951</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>Okay. And then just as a follow-up. Just on th...</td>\n",
       "      <td>0.981843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>0.027964</td>\n",
       "      <td>0.025987</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.087217</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Stephen Scherr</td>\n",
       "      <td>0.858832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amazon_score_mixed  amazon_score_negative  amazon_score_neutral  \\\n",
       "0               0.001549               0.000533              0.750581   \n",
       "1               0.009229               0.006072              0.880566   \n",
       "2               0.000831               0.008268              0.980631   \n",
       "3               0.011638               0.953385              0.034877   \n",
       "4               0.014957               0.000221              0.007328   \n",
       "5               0.014018               0.019320              0.291906   \n",
       "6               0.451327               0.037996              0.373289   \n",
       "7               0.004365               0.080391              0.883574   \n",
       "8               0.000836               0.000162              0.717327   \n",
       "9               0.000758               0.000017              0.637107   \n",
       "10              0.003000               0.000022              0.051867   \n",
       "11              0.014933               0.287314              0.694258   \n",
       "12              0.028350               0.082266              0.638542   \n",
       "13              0.000287               0.000059              0.990345   \n",
       "14              0.029805               0.006176              0.890847   \n",
       "15              0.000345               0.000182              0.968123   \n",
       "16              0.001400               0.000614              0.828256   \n",
       "17              0.004581               0.399467              0.595677   \n",
       "18              0.001532               0.000968              0.942365   \n",
       "19              0.000022               0.000011              0.996916   \n",
       "20              0.000131               0.000046              0.990362   \n",
       "21              0.000911               0.004844              0.993256   \n",
       "22              0.025572               0.316995              0.651127   \n",
       "23              0.011930               0.026225              0.943055   \n",
       "24              0.005882               0.003226              0.943089   \n",
       "25              0.074492               0.231137              0.380990   \n",
       "26              0.059969               0.172489              0.718136   \n",
       "27              0.013141               0.000841              0.090313   \n",
       "28              0.004911               0.001716              0.939778   \n",
       "29              0.020755               0.209473              0.759121   \n",
       "...                  ...                    ...                   ...   \n",
       "1614            0.005463               0.113443              0.864094   \n",
       "1615            0.015355               0.245939              0.690269   \n",
       "1616            0.007706               0.006098              0.956241   \n",
       "1617            0.002943               0.008180              0.923570   \n",
       "1618            0.054751               0.190050              0.729713   \n",
       "1619            0.046867               0.037659              0.778988   \n",
       "1620            0.000823               0.001687              0.981933   \n",
       "1621            0.015355               0.245939              0.690269   \n",
       "1622            0.014219               0.078054              0.875139   \n",
       "1623            0.002943               0.008180              0.923570   \n",
       "1624            0.070567               0.417806              0.470117   \n",
       "1625            0.062484               0.152350              0.674526   \n",
       "1626            0.004006               0.021840              0.939878   \n",
       "1627            0.001839               0.022030              0.966246   \n",
       "1628            0.001313               0.006578              0.980603   \n",
       "1629            0.015202               0.064148              0.916375   \n",
       "1630            0.002943               0.008180              0.923570   \n",
       "1631            0.003587               0.069386              0.915397   \n",
       "1632            0.052466               0.630312              0.309089   \n",
       "1633            0.001313               0.006578              0.980603   \n",
       "1634            0.217418               0.002583              0.243894   \n",
       "1635            0.002943               0.008180              0.923570   \n",
       "1636            0.067419               0.029362              0.266760   \n",
       "1637            0.004006               0.021840              0.939878   \n",
       "1638            0.003722               0.053312              0.929166   \n",
       "1639            0.001829               0.005262              0.971907   \n",
       "1640            0.037598               0.040455              0.734124   \n",
       "1641            0.002943               0.008180              0.923570   \n",
       "1642            0.001491               0.007209              0.981843   \n",
       "1643            0.027964               0.025987              0.858832   \n",
       "\n",
       "      amazon_score_positive amazon_sentiments_label azure_api_label  \\\n",
       "0                  0.247337                 neutral        positive   \n",
       "1                  0.104133                 neutral         neutral   \n",
       "2                  0.010270                 neutral         neutral   \n",
       "3                  0.000099                negative         neutral   \n",
       "4                  0.977495                positive        positive   \n",
       "5                  0.674756                positive        positive   \n",
       "6                  0.137388                   mixed        positive   \n",
       "7                  0.031670                 neutral         neutral   \n",
       "8                  0.281674                 neutral         neutral   \n",
       "9                  0.362118                 neutral         neutral   \n",
       "10                 0.945111                positive        positive   \n",
       "11                 0.003495                 neutral         neutral   \n",
       "12                 0.250842                 neutral         neutral   \n",
       "13                 0.009309                 neutral         neutral   \n",
       "14                 0.073172                 neutral         neutral   \n",
       "15                 0.031350                 neutral        positive   \n",
       "16                 0.169730                 neutral         neutral   \n",
       "17                 0.000274                 neutral        positive   \n",
       "18                 0.055135                 neutral         neutral   \n",
       "19                 0.003051                 neutral         neutral   \n",
       "20                 0.009461                 neutral         neutral   \n",
       "21                 0.000989                 neutral         neutral   \n",
       "22                 0.006305                 neutral        negative   \n",
       "23                 0.018790                 neutral         neutral   \n",
       "24                 0.047803                 neutral         neutral   \n",
       "25                 0.313381                 neutral         neutral   \n",
       "26                 0.049406                 neutral        negative   \n",
       "27                 0.895706                positive        positive   \n",
       "28                 0.053595                 neutral         neutral   \n",
       "29                 0.010652                 neutral         neutral   \n",
       "...                     ...                     ...             ...   \n",
       "1614               0.017000                 neutral         neutral   \n",
       "1615               0.048437                 neutral         neutral   \n",
       "1616               0.029955                 neutral         neutral   \n",
       "1617               0.065307                 neutral        positive   \n",
       "1618               0.025485                 neutral        positive   \n",
       "1619               0.136486                 neutral        positive   \n",
       "1620               0.015556                 neutral         neutral   \n",
       "1621               0.048437                 neutral         neutral   \n",
       "1622               0.032589                 neutral         neutral   \n",
       "1623               0.065307                 neutral         neutral   \n",
       "1624               0.041511                 neutral         neutral   \n",
       "1625               0.110639                 neutral         neutral   \n",
       "1626               0.034276                 neutral         neutral   \n",
       "1627               0.009884                 neutral         neutral   \n",
       "1628               0.011507                 neutral         neutral   \n",
       "1629               0.004275                 neutral         neutral   \n",
       "1630               0.065307                 neutral        positive   \n",
       "1631               0.011630                 neutral         neutral   \n",
       "1632               0.008132                negative         neutral   \n",
       "1633               0.011507                 neutral         neutral   \n",
       "1634               0.536106                positive         neutral   \n",
       "1635               0.065307                 neutral         neutral   \n",
       "1636               0.636460                positive         neutral   \n",
       "1637               0.034276                 neutral         neutral   \n",
       "1638               0.013800                 neutral         neutral   \n",
       "1639               0.021002                 neutral         neutral   \n",
       "1640               0.187823                 neutral         neutral   \n",
       "1641               0.065307                 neutral         neutral   \n",
       "1642               0.009457                 neutral         neutral   \n",
       "1643               0.087217                 neutral         neutral   \n",
       "\n",
       "      azure_api_score google_sentiment_label  google_sentiment_magnitude  \\\n",
       "0            0.978328               positive                         1.1   \n",
       "1            0.500000               positive                         1.4   \n",
       "2            0.500000                neutral                         0.0   \n",
       "3            0.500000               negative                         1.2   \n",
       "4            0.905933               positive                         7.9   \n",
       "5            0.904133                neutral                         0.1   \n",
       "6            0.832192                neutral                         3.3   \n",
       "7            0.500000                neutral                         0.1   \n",
       "8            0.500000               positive                         1.3   \n",
       "9            0.748680               positive                         2.6   \n",
       "10           0.952201               positive                         1.4   \n",
       "11           0.500000               negative                         1.5   \n",
       "12           0.500000               positive                         2.8   \n",
       "13           0.500000               positive                         2.4   \n",
       "14           0.500000                neutral                         1.7   \n",
       "15           0.915934               positive                         1.5   \n",
       "16           0.500000               positive                         1.7   \n",
       "17           0.800259                neutral                         0.4   \n",
       "18           0.500000                neutral                         1.9   \n",
       "19           0.500000                neutral                         0.8   \n",
       "20           0.500000                neutral                         0.5   \n",
       "21           0.500000                neutral                         0.5   \n",
       "22           0.186991                neutral                         0.3   \n",
       "23           0.500000                neutral                         0.6   \n",
       "24           0.500000                neutral                         0.2   \n",
       "25           0.500000                neutral                         1.0   \n",
       "26           0.229010                neutral                         2.0   \n",
       "27           0.889206               positive                         3.1   \n",
       "28           0.500000                neutral                         0.2   \n",
       "29           0.500000                neutral                         0.5   \n",
       "...               ...                    ...                         ...   \n",
       "1614         0.500000                neutral                         0.7   \n",
       "1615         0.500000                neutral                         0.2   \n",
       "1616         0.500000                neutral                         0.8   \n",
       "1617         0.823326               positive                         1.5   \n",
       "1618         0.832761               positive                         2.0   \n",
       "1619         0.853107                neutral                         0.3   \n",
       "1620         0.500000                neutral                         0.1   \n",
       "1621         0.500000                neutral                         0.0   \n",
       "1622         0.500000                neutral                         0.0   \n",
       "1623         0.500000                neutral                         0.1   \n",
       "1624         0.500000                neutral                         0.0   \n",
       "1625         0.500000                neutral                         1.0   \n",
       "1626         0.500000                neutral                         0.1   \n",
       "1627         0.500000                neutral                         1.3   \n",
       "1628         0.500000                neutral                         2.8   \n",
       "1629         0.500000                neutral                         0.0   \n",
       "1630         0.898174               positive                         2.7   \n",
       "1631         0.500000                neutral                         0.0   \n",
       "1632         0.500000               positive                         3.7   \n",
       "1633         0.500000                neutral                         0.0   \n",
       "1634         0.500000                neutral                         0.0   \n",
       "1635         0.500000                neutral                         0.0   \n",
       "1636         0.748757                neutral                         0.0   \n",
       "1637         0.500000                neutral                         1.0   \n",
       "1638         0.500000                neutral                         0.1   \n",
       "1639         0.500000               positive                         4.6   \n",
       "1640         0.500000                neutral                         0.6   \n",
       "1641         0.748757                neutral                         0.0   \n",
       "1642         0.500000                neutral                         1.0   \n",
       "1643         0.500000                neutral                         0.1   \n",
       "\n",
       "      google_sentiment_socre  ibm_score ibm_sentiments_label sentiment  \\\n",
       "0                        0.2   0.816136             positive  positive   \n",
       "1                        0.2   0.558518             positive  positive   \n",
       "2                        0.0   0.000000              neutral   neutral   \n",
       "3                       -0.3  -0.598559             negative  negative   \n",
       "4                        0.5   0.790615             positive  negative   \n",
       "5                        0.0   0.988573             positive  positive   \n",
       "6                        0.1   0.574769             positive  negative   \n",
       "7                        0.0  -0.586947             negative   neutral   \n",
       "8                        0.4   0.884016             positive  positive   \n",
       "9                        0.6   0.598940             positive  positive   \n",
       "10                       0.4   0.875206             positive  positive   \n",
       "11                      -0.3  -0.558735             negative   neutral   \n",
       "12                       0.2   0.569009             positive  negative   \n",
       "13                       0.4   0.775907             positive  positive   \n",
       "14                       0.0   0.564156             positive   neutral   \n",
       "15                       0.5   0.926254             positive  positive   \n",
       "16                       0.2   0.633038             positive  positive   \n",
       "17                       0.0  -0.677819             negative  positive   \n",
       "18                       0.0   0.732119             positive  positive   \n",
       "19                       0.2   0.681920             positive   neutral   \n",
       "20                       0.0   0.577718             positive  positive   \n",
       "21                       0.0  -0.287068             negative  negative   \n",
       "22                      -0.1  -0.844607             negative   neutral   \n",
       "23                       0.1   0.355513             positive   neutral   \n",
       "24                      -0.2   0.662070             positive   neutral   \n",
       "25                       0.1   0.523252             positive  positive   \n",
       "26                       0.0  -0.309086             negative  positive   \n",
       "27                       0.4   0.705426             positive  positive   \n",
       "28                       0.0  -0.346326             negative   neutral   \n",
       "29                       0.0  -0.385726             negative   neutral   \n",
       "...                      ...        ...                  ...       ...   \n",
       "1614                     0.0   0.744958             positive  positive   \n",
       "1615                     0.0   0.607678             positive  positive   \n",
       "1616                     0.0   0.290116             positive  positive   \n",
       "1617                     0.3   0.985956             positive  positive   \n",
       "1618                     0.5   0.837670             positive  positive   \n",
       "1619                     0.3   0.943123             positive   neutral   \n",
       "1620                    -0.1   0.000000              neutral   neutral   \n",
       "1621                     0.0   0.000000              neutral   neutral   \n",
       "1622                     0.0   0.000000              neutral   neutral   \n",
       "1623                     0.0   0.000000              neutral   neutral   \n",
       "1624                     0.0   0.000000              neutral   neutral   \n",
       "1625                     0.1  -0.488886             negative   neutral   \n",
       "1626                     0.1   0.791219             positive   neutral   \n",
       "1627                     0.0   0.801530             positive   neutral   \n",
       "1628                     0.1   0.637414             positive  positive   \n",
       "1629                     0.0   0.000000              neutral   neutral   \n",
       "1630                     0.2   0.555948             positive   neutral   \n",
       "1631                     0.0   0.000000              neutral   neutral   \n",
       "1632                     0.2   0.759198             positive  positive   \n",
       "1633                     0.0   0.000000              neutral   neutral   \n",
       "1634                     0.0   0.000000              neutral   neutral   \n",
       "1635                     0.0   0.000000              neutral   neutral   \n",
       "1636                     0.0   0.000000              neutral   neutral   \n",
       "1637                     0.2  -0.357957             negative  positive   \n",
       "1638                     0.1   0.791219             positive   neutral   \n",
       "1639                     0.2   0.767542             positive  positive   \n",
       "1640                     0.0   0.274780             positive  positive   \n",
       "1641                     0.0   0.000000              neutral   neutral   \n",
       "1642                     0.1   0.420951             positive  negative   \n",
       "1643                     0.1   0.791219             positive   neutral   \n",
       "\n",
       "                                                   text  \\\n",
       "0     Thank you. Good afternoon, everyone. And welco...   \n",
       "1     As we look past Q1, we expect the channel inve...   \n",
       "2     And your last question comes from the line of ...   \n",
       "3     On the China gaming weakness, is it the slower...   \n",
       "4     I don't know that we could tear that apart, te...   \n",
       "5     Thank you. I'll now turn the call back over to...   \n",
       "6     2018 was a record year but it was a disappoint...   \n",
       "7     And this concludes today's conference call. Yo...   \n",
       "8     In addition, we announced a record of 40 plus ...   \n",
       "9     We're also pleased to see growing momentum in ...   \n",
       "10    Pairing DLSS with ray tracing can provide comp...   \n",
       "11    Moving to data center. Revenue was $679 millio...   \n",
       "12    In addition, hyperscale and cloud purchases de...   \n",
       "13    For example, we recently announced RAPIDS, our...   \n",
       "14    Our visibility remains low in the current caut...   \n",
       "15    We have also strengthened our product portfoli...   \n",
       "16    Moving to pro visualization, revenue reached $...   \n",
       "17    The webcast will be available for replay until...   \n",
       "18    Finally, turning to automotive. Q4 revenue was...   \n",
       "19    To deliver these capabilities, DRIVE AutoPilot...   \n",
       "20    Mercedes-Benz has also chosen NVIDIA for its n...   \n",
       "21    Moving to the rest of the P&L and balance shee...   \n",
       "22    With that, let me turn to the outlook for the ...   \n",
       "23    For fiscal 2020, we expect Q1 to mark the bott...   \n",
       "24    In closing, I'd like to highlight upcoming eve...   \n",
       "25    I had two questions. First, Colette, you talke...   \n",
       "26    When we launched the 2070 and 2080, it was the...   \n",
       "27    And I think that right out of the box, it deli...   \n",
       "28    During this call, we may make forward-looking ...   \n",
       "29    So Toshiya to answer your second question rega...   \n",
       "...                                                 ...   \n",
       "1614  Turning to Page 13 on Capital. Our Common Equi...   \n",
       "1615  For the full year, we repurchased 13.9 million...   \n",
       "1616  Turning to balance sheet and liquidity on Page...   \n",
       "1617  Before taking questions, a few closing thought...   \n",
       "1618  Lastly, the management team is motivated by th...   \n",
       "1619  With that, thanks again for dialing in, and we...   \n",
       "1620                        Question-and-Answer Session   \n",
       "1621                                           Operator   \n",
       "1622              Michael Mayo - Wells Fargo Securities   \n",
       "1623  [Operator Instructions]. Your first question i...   \n",
       "1624                                       Glenn Schorr   \n",
       "1625  And I want to talk about I&L. And it's a combo...   \n",
       "1626                                     Stephen Scherr   \n",
       "1627  Sure. Thanks, Glenn. I appreciate the question...   \n",
       "1628  And together, those five names contributed to ...   \n",
       "1629                                       Glenn Schorr   \n",
       "1630  Okay. That's all very helpful, and it sets up ...   \n",
       "1631                                      David Solomon   \n",
       "1632  So I'll start, Glenn, and I'll just comment. O...   \n",
       "1633          Chinedu Bolu - Sanford C. Bernstein & Co.   \n",
       "1634                                           Operator   \n",
       "1635  Your next question is from the line of Michael...   \n",
       "1636                                    Michael Carrier   \n",
       "1637  Stephen, maybe one more, just on the I&L busin...   \n",
       "1638                                     Stephen Scherr   \n",
       "1639  Sure. Thanks for the question. I think it's di...   \n",
       "1640  And that has thrown up, as I said in my commen...   \n",
       "1641                                    Michael Carrier   \n",
       "1642  Okay. And then just as a follow-up. Just on th...   \n",
       "1643                                     Stephen Scherr   \n",
       "\n",
       "      amazon_sentiment_score  \n",
       "0                   0.750581  \n",
       "1                   0.880566  \n",
       "2                   0.980631  \n",
       "3                   0.953385  \n",
       "4                   0.977495  \n",
       "5                   0.674756  \n",
       "6                   0.373289  \n",
       "7                   0.883574  \n",
       "8                   0.717327  \n",
       "9                   0.637107  \n",
       "10                  0.945111  \n",
       "11                  0.694258  \n",
       "12                  0.638542  \n",
       "13                  0.990345  \n",
       "14                  0.890847  \n",
       "15                  0.968123  \n",
       "16                  0.828256  \n",
       "17                  0.595677  \n",
       "18                  0.942365  \n",
       "19                  0.996916  \n",
       "20                  0.990362  \n",
       "21                  0.993256  \n",
       "22                  0.651127  \n",
       "23                  0.943055  \n",
       "24                  0.943089  \n",
       "25                  0.380990  \n",
       "26                  0.718136  \n",
       "27                  0.895706  \n",
       "28                  0.939778  \n",
       "29                  0.759121  \n",
       "...                      ...  \n",
       "1614                0.864094  \n",
       "1615                0.690269  \n",
       "1616                0.956241  \n",
       "1617                0.923570  \n",
       "1618                0.729713  \n",
       "1619                0.778988  \n",
       "1620                0.981933  \n",
       "1621                0.690269  \n",
       "1622                0.875139  \n",
       "1623                0.923570  \n",
       "1624                0.470117  \n",
       "1625                0.674526  \n",
       "1626                0.939878  \n",
       "1627                0.966246  \n",
       "1628                0.980603  \n",
       "1629                0.916375  \n",
       "1630                0.923570  \n",
       "1631                0.915397  \n",
       "1632                0.630312  \n",
       "1633                0.980603  \n",
       "1634                0.536106  \n",
       "1635                0.923570  \n",
       "1636                0.636460  \n",
       "1637                0.939878  \n",
       "1638                0.929166  \n",
       "1639                0.971907  \n",
       "1640                0.734124  \n",
       "1641                0.923570  \n",
       "1642                0.981843  \n",
       "1643                0.858832  \n",
       "\n",
       "[1644 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980631</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>0.953385</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>0.674756</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.832192</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.574769</td>\n",
       "      <td>0.373289</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.586947</td>\n",
       "      <td>0.883574</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.884016</td>\n",
       "      <td>0.717327</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.748680</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>0.637107</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.952201</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.875206</td>\n",
       "      <td>0.945111</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.558735</td>\n",
       "      <td>0.694258</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.569009</td>\n",
       "      <td>0.638542</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.775907</td>\n",
       "      <td>0.990345</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564156</td>\n",
       "      <td>0.890847</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.915934</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>0.968123</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.633038</td>\n",
       "      <td>0.828256</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.800259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.677819</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.732119</td>\n",
       "      <td>0.942365</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.681920</td>\n",
       "      <td>0.996916</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.577718</td>\n",
       "      <td>0.990362</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.287068</td>\n",
       "      <td>0.993256</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.186991</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.844607</td>\n",
       "      <td>0.651127</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.355513</td>\n",
       "      <td>0.943055</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.662070</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.523252</td>\n",
       "      <td>0.380990</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.229010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.309086</td>\n",
       "      <td>0.718136</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.889206</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.705426</td>\n",
       "      <td>0.895706</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.346326</td>\n",
       "      <td>0.939778</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.385726</td>\n",
       "      <td>0.759121</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744958</td>\n",
       "      <td>0.864094</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607678</td>\n",
       "      <td>0.690269</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290116</td>\n",
       "      <td>0.956241</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.823326</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.985956</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0.832761</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.837670</td>\n",
       "      <td>0.729713</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>0.853107</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.943123</td>\n",
       "      <td>0.778988</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.690269</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.875139</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1623</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470117</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.488886</td>\n",
       "      <td>0.674526</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.939878</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.801530</td>\n",
       "      <td>0.966246</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.637414</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.916375</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>0.898174</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555948</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915397</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.759198</td>\n",
       "      <td>0.630312</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.980603</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536106</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.748757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636460</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.357957</td>\n",
       "      <td>0.939878</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.929166</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.767542</td>\n",
       "      <td>0.971907</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274780</td>\n",
       "      <td>0.734124</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.748757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923570</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.420951</td>\n",
       "      <td>0.981843</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      azure_api_score  google_sentiment_socre  ibm_score  \\\n",
       "0            0.978328                     0.2   0.816136   \n",
       "1            0.500000                     0.2   0.558518   \n",
       "2            0.500000                     0.0   0.000000   \n",
       "3            0.500000                    -0.3  -0.598559   \n",
       "4            0.905933                     0.5   0.790615   \n",
       "5            0.904133                     0.0   0.988573   \n",
       "6            0.832192                     0.1   0.574769   \n",
       "7            0.500000                     0.0  -0.586947   \n",
       "8            0.500000                     0.4   0.884016   \n",
       "9            0.748680                     0.6   0.598940   \n",
       "10           0.952201                     0.4   0.875206   \n",
       "11           0.500000                    -0.3  -0.558735   \n",
       "12           0.500000                     0.2   0.569009   \n",
       "13           0.500000                     0.4   0.775907   \n",
       "14           0.500000                     0.0   0.564156   \n",
       "15           0.915934                     0.5   0.926254   \n",
       "16           0.500000                     0.2   0.633038   \n",
       "17           0.800259                     0.0  -0.677819   \n",
       "18           0.500000                     0.0   0.732119   \n",
       "19           0.500000                     0.2   0.681920   \n",
       "20           0.500000                     0.0   0.577718   \n",
       "21           0.500000                     0.0  -0.287068   \n",
       "22           0.186991                    -0.1  -0.844607   \n",
       "23           0.500000                     0.1   0.355513   \n",
       "24           0.500000                    -0.2   0.662070   \n",
       "25           0.500000                     0.1   0.523252   \n",
       "26           0.229010                     0.0  -0.309086   \n",
       "27           0.889206                     0.4   0.705426   \n",
       "28           0.500000                     0.0  -0.346326   \n",
       "29           0.500000                     0.0  -0.385726   \n",
       "...               ...                     ...        ...   \n",
       "1614         0.500000                     0.0   0.744958   \n",
       "1615         0.500000                     0.0   0.607678   \n",
       "1616         0.500000                     0.0   0.290116   \n",
       "1617         0.823326                     0.3   0.985956   \n",
       "1618         0.832761                     0.5   0.837670   \n",
       "1619         0.853107                     0.3   0.943123   \n",
       "1620         0.500000                    -0.1   0.000000   \n",
       "1621         0.500000                     0.0   0.000000   \n",
       "1622         0.500000                     0.0   0.000000   \n",
       "1623         0.500000                     0.0   0.000000   \n",
       "1624         0.500000                     0.0   0.000000   \n",
       "1625         0.500000                     0.1  -0.488886   \n",
       "1626         0.500000                     0.1   0.791219   \n",
       "1627         0.500000                     0.0   0.801530   \n",
       "1628         0.500000                     0.1   0.637414   \n",
       "1629         0.500000                     0.0   0.000000   \n",
       "1630         0.898174                     0.2   0.555948   \n",
       "1631         0.500000                     0.0   0.000000   \n",
       "1632         0.500000                     0.2   0.759198   \n",
       "1633         0.500000                     0.0   0.000000   \n",
       "1634         0.500000                     0.0   0.000000   \n",
       "1635         0.500000                     0.0   0.000000   \n",
       "1636         0.748757                     0.0   0.000000   \n",
       "1637         0.500000                     0.2  -0.357957   \n",
       "1638         0.500000                     0.1   0.791219   \n",
       "1639         0.500000                     0.2   0.767542   \n",
       "1640         0.500000                     0.0   0.274780   \n",
       "1641         0.748757                     0.0   0.000000   \n",
       "1642         0.500000                     0.1   0.420951   \n",
       "1643         0.500000                     0.1   0.791219   \n",
       "\n",
       "      amazon_sentiment_score sentiment  \n",
       "0                   0.750581  positive  \n",
       "1                   0.880566  positive  \n",
       "2                   0.980631   neutral  \n",
       "3                   0.953385  negative  \n",
       "4                   0.977495  negative  \n",
       "5                   0.674756  positive  \n",
       "6                   0.373289  negative  \n",
       "7                   0.883574   neutral  \n",
       "8                   0.717327  positive  \n",
       "9                   0.637107  positive  \n",
       "10                  0.945111  positive  \n",
       "11                  0.694258   neutral  \n",
       "12                  0.638542  negative  \n",
       "13                  0.990345  positive  \n",
       "14                  0.890847   neutral  \n",
       "15                  0.968123  positive  \n",
       "16                  0.828256  positive  \n",
       "17                  0.595677  positive  \n",
       "18                  0.942365  positive  \n",
       "19                  0.996916   neutral  \n",
       "20                  0.990362  positive  \n",
       "21                  0.993256  negative  \n",
       "22                  0.651127   neutral  \n",
       "23                  0.943055   neutral  \n",
       "24                  0.943089   neutral  \n",
       "25                  0.380990  positive  \n",
       "26                  0.718136  positive  \n",
       "27                  0.895706  positive  \n",
       "28                  0.939778   neutral  \n",
       "29                  0.759121   neutral  \n",
       "...                      ...       ...  \n",
       "1614                0.864094  positive  \n",
       "1615                0.690269  positive  \n",
       "1616                0.956241  positive  \n",
       "1617                0.923570  positive  \n",
       "1618                0.729713  positive  \n",
       "1619                0.778988   neutral  \n",
       "1620                0.981933   neutral  \n",
       "1621                0.690269   neutral  \n",
       "1622                0.875139   neutral  \n",
       "1623                0.923570   neutral  \n",
       "1624                0.470117   neutral  \n",
       "1625                0.674526   neutral  \n",
       "1626                0.939878   neutral  \n",
       "1627                0.966246   neutral  \n",
       "1628                0.980603  positive  \n",
       "1629                0.916375   neutral  \n",
       "1630                0.923570   neutral  \n",
       "1631                0.915397   neutral  \n",
       "1632                0.630312  positive  \n",
       "1633                0.980603   neutral  \n",
       "1634                0.536106   neutral  \n",
       "1635                0.923570   neutral  \n",
       "1636                0.636460   neutral  \n",
       "1637                0.939878  positive  \n",
       "1638                0.929166   neutral  \n",
       "1639                0.971907  positive  \n",
       "1640                0.734124  positive  \n",
       "1641                0.923570   neutral  \n",
       "1642                0.981843  negative  \n",
       "1643                0.858832   neutral  \n",
       "\n",
       "[1644 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keeping only the columns we need for mapping the label we assigned it with the scores of all 4 API's. \n",
    "sentiment_df = sentiment[['azure_api_score', 'google_sentiment_socre','ibm_score','amazon_sentiment_score','sentiment']]\n",
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1644, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>0.953385</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>0.674756</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azure_api_score  google_sentiment_socre  ibm_score  amazon_sentiment_score  \\\n",
       "0         0.978328                     0.2   0.816136                0.750581   \n",
       "1         0.500000                     0.2   0.558518                0.880566   \n",
       "3         0.500000                    -0.3  -0.598559                0.953385   \n",
       "4         0.905933                     0.5   0.790615                0.977495   \n",
       "5         0.904133                     0.0   0.988573                0.674756   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "3  negative  \n",
       "4  negative  \n",
       "5  positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the neutral sentiments for our model\n",
    "\n",
    "sentiment_df = sentiment_df[sentiment_df['sentiment'] != 'neutral']\n",
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(811, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Build a model to map the output Sentiement label with the sentiment scores from all 4 apis\n",
    "\n",
    "#label encode the output variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "sentiment_df['sentiment'] = le.fit_transform(sentiment_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.750581</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>0.880566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>0.953385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>0.977495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>0.674756</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azure_api_score  google_sentiment_socre  ibm_score  amazon_sentiment_score  \\\n",
       "0         0.978328                     0.2   0.816136                0.750581   \n",
       "1         0.500000                     0.2   0.558518                0.880566   \n",
       "3         0.500000                    -0.3  -0.598559                0.953385   \n",
       "4         0.905933                     0.5   0.790615                0.977495   \n",
       "5         0.904133                     0.0   0.988573                0.674756   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "3          0  \n",
       "4          0  \n",
       "5          1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['azure_api_score', 'google_sentiment_socre', 'ibm_score',\n",
       "       'amazon_sentiment_score'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = sentiment_df.iloc[:,:-1]\n",
    "Y = sentiment_df.iloc[:,-1]\n",
    "features = X.columns.values\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.816136</td>\n",
       "      <td>0.750581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558518</td>\n",
       "      <td>0.880566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.598559</td>\n",
       "      <td>0.953385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.790615</td>\n",
       "      <td>0.977495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.904133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988573</td>\n",
       "      <td>0.674756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azure_api_score  google_sentiment_socre  ibm_score  amazon_sentiment_score\n",
       "0         0.978328                     0.2   0.816136                0.750581\n",
       "1         0.500000                     0.2   0.558518                0.880566\n",
       "3         0.500000                    -0.3  -0.598559                0.953385\n",
       "4         0.905933                     0.5   0.790615                0.977495\n",
       "5         0.904133                     0.0   0.988573                0.674756"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "3    0\n",
       "4    0\n",
       "5    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling all variables to a range of 0 to 1\n",
    "sc = MinMaxScaler(feature_range= (0,1))\n",
    "X = pd.DataFrame(sc.fit_transform(X), columns= features)\n",
    "#features = X.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azure_api_score</th>\n",
       "      <th>google_sentiment_socre</th>\n",
       "      <th>ibm_score</th>\n",
       "      <th>amazon_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.980185</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.903736</td>\n",
       "      <td>0.646323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.468419</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.767878</td>\n",
       "      <td>0.831746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468419</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.157679</td>\n",
       "      <td>0.935622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.902730</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>0.970015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.900803</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.994673</td>\n",
       "      <td>0.538159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   azure_api_score  google_sentiment_socre  ibm_score  amazon_sentiment_score\n",
       "0         0.980185                  0.5625   0.903736                0.646323\n",
       "1         0.468419                  0.5625   0.767878                0.831746\n",
       "2         0.468419                  0.2500   0.157679                0.935622\n",
       "3         0.902730                  0.7500   0.890277                0.970015\n",
       "4         0.900803                  0.4375   0.994673                0.538159"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 705\n",
      "Trainable params: 705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(32, activation='relu', kernel_initializer='uniform', input_shape=(4,)))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation='relu',kernel_initializer='uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 648 samples, validate on 163 samples\n",
      "Epoch 1/20\n",
      "648/648 [==============================] - ETA: 2:36 - loss: 0.6932 - acc: 0.0000e+0 - ETA: 3s - loss: 0.6835 - acc: 0.8333      - ETA: 1s - loss: 0.6654 - acc: 0.812 - ETA: 0s - loss: 0.6425 - acc: 0.784 - ETA: 0s - loss: 0.5936 - acc: 0.804 - ETA: 0s - loss: 0.5675 - acc: 0.805 - ETA: 0s - loss: 0.5548 - acc: 0.805 - 1s 1ms/step - loss: 0.5503 - acc: 0.8025 - val_loss: 0.4616 - val_acc: 0.8098\n",
      "Epoch 2/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2274 - acc: 1.000 - ETA: 0s - loss: 0.4418 - acc: 0.846 - ETA: 0s - loss: 0.4722 - acc: 0.820 - ETA: 0s - loss: 0.4824 - acc: 0.809 - ETA: 0s - loss: 0.4697 - acc: 0.815 - ETA: 0s - loss: 0.4775 - acc: 0.810 - ETA: 0s - loss: 0.4837 - acc: 0.804 - ETA: 0s - loss: 0.4816 - acc: 0.806 - ETA: 0s - loss: 0.4790 - acc: 0.810 - ETA: 0s - loss: 0.4845 - acc: 0.803 - ETA: 0s - loss: 0.4871 - acc: 0.801 - ETA: 0s - loss: 0.4809 - acc: 0.806 - 1s 1ms/step - loss: 0.4807 - acc: 0.8056 - val_loss: 0.4584 - val_acc: 0.8098\n",
      "Epoch 3/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1760 - acc: 1.000 - ETA: 0s - loss: 0.4893 - acc: 0.800 - ETA: 0s - loss: 0.5275 - acc: 0.785 - ETA: 0s - loss: 0.5378 - acc: 0.780 - ETA: 0s - loss: 0.5089 - acc: 0.798 - ETA: 0s - loss: 0.5033 - acc: 0.804 - ETA: 0s - loss: 0.4850 - acc: 0.816 - ETA: 0s - loss: 0.4770 - acc: 0.815 - ETA: 0s - loss: 0.4940 - acc: 0.805 - ETA: 0s - loss: 0.4761 - acc: 0.816 - ETA: 0s - loss: 0.4812 - acc: 0.811 - ETA: 0s - loss: 0.4857 - acc: 0.805 - ETA: 0s - loss: 0.4813 - acc: 0.808 - 1s 1ms/step - loss: 0.4859 - acc: 0.8056 - val_loss: 0.4578 - val_acc: 0.8098\n",
      "Epoch 4/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2487 - acc: 1.000 - ETA: 0s - loss: 0.5119 - acc: 0.765 - ETA: 0s - loss: 0.5909 - acc: 0.712 - ETA: 0s - loss: 0.5407 - acc: 0.755 - ETA: 0s - loss: 0.5298 - acc: 0.770 - ETA: 0s - loss: 0.5020 - acc: 0.788 - ETA: 0s - loss: 0.4858 - acc: 0.800 - ETA: 0s - loss: 0.4848 - acc: 0.801 - ETA: 0s - loss: 0.4768 - acc: 0.806 - 0s 753us/step - loss: 0.4757 - acc: 0.8056 - val_loss: 0.4526 - val_acc: 0.8098\n",
      "Epoch 5/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1701 - acc: 1.000 - ETA: 0s - loss: 0.3192 - acc: 0.900 - ETA: 0s - loss: 0.4360 - acc: 0.831 - ETA: 0s - loss: 0.4424 - acc: 0.825 - ETA: 0s - loss: 0.4556 - acc: 0.818 - ETA: 0s - loss: 0.4682 - acc: 0.808 - ETA: 0s - loss: 0.4670 - acc: 0.808 - 0s 585us/step - loss: 0.4691 - acc: 0.8056 - val_loss: 0.4511 - val_acc: 0.8098\n",
      "Epoch 6/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1985 - acc: 1.000 - ETA: 0s - loss: 0.4484 - acc: 0.842 - ETA: 0s - loss: 0.4464 - acc: 0.837 - ETA: 0s - loss: 0.4460 - acc: 0.830 - ETA: 0s - loss: 0.4467 - acc: 0.823 - ETA: 0s - loss: 0.4713 - acc: 0.808 - ETA: 0s - loss: 0.4891 - acc: 0.794 - ETA: 0s - loss: 0.4853 - acc: 0.798 - 0s 651us/step - loss: 0.4761 - acc: 0.8056 - val_loss: 0.4485 - val_acc: 0.8098\n",
      "Epoch 7/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1925 - acc: 1.000 - ETA: 0s - loss: 0.4502 - acc: 0.817 - ETA: 0s - loss: 0.4909 - acc: 0.799 - ETA: 0s - loss: 0.4774 - acc: 0.807 - ETA: 0s - loss: 0.4781 - acc: 0.804 - ETA: 0s - loss: 0.4826 - acc: 0.802 - ETA: 0s - loss: 0.4833 - acc: 0.802 - 0s 591us/step - loss: 0.4775 - acc: 0.8056 - val_loss: 0.4453 - val_acc: 0.8098\n",
      "Epoch 8/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1631 - acc: 1.000 - ETA: 0s - loss: 0.4285 - acc: 0.825 - ETA: 0s - loss: 0.4776 - acc: 0.793 - ETA: 0s - loss: 0.4483 - acc: 0.817 - ETA: 0s - loss: 0.4542 - acc: 0.814 - ETA: 0s - loss: 0.4414 - acc: 0.820 - ETA: 0s - loss: 0.4526 - acc: 0.812 - ETA: 0s - loss: 0.4540 - acc: 0.812 - 0s 653us/step - loss: 0.4663 - acc: 0.8056 - val_loss: 0.4474 - val_acc: 0.8098\n",
      "Epoch 9/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2630 - acc: 1.000 - ETA: 0s - loss: 0.4419 - acc: 0.818 - ETA: 0s - loss: 0.5059 - acc: 0.782 - ETA: 0s - loss: 0.4865 - acc: 0.792 - ETA: 0s - loss: 0.4842 - acc: 0.793 - ETA: 0s - loss: 0.4769 - acc: 0.799 - ETA: 0s - loss: 0.4766 - acc: 0.803 - ETA: 0s - loss: 0.4626 - acc: 0.812 - 0s 666us/step - loss: 0.4735 - acc: 0.8056 - val_loss: 0.4400 - val_acc: 0.8098\n",
      "Epoch 10/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2013 - acc: 1.000 - ETA: 0s - loss: 0.5212 - acc: 0.792 - ETA: 0s - loss: 0.4892 - acc: 0.810 - ETA: 0s - loss: 0.4684 - acc: 0.817 - ETA: 0s - loss: 0.4509 - acc: 0.826 - ETA: 0s - loss: 0.4666 - acc: 0.814 - ETA: 0s - loss: 0.4708 - acc: 0.809 - ETA: 0s - loss: 0.4783 - acc: 0.804 - 0s 666us/step - loss: 0.4737 - acc: 0.8056 - val_loss: 0.4377 - val_acc: 0.8098\n",
      "Epoch 11/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1810 - acc: 1.000 - ETA: 0s - loss: 0.3779 - acc: 0.845 - ETA: 0s - loss: 0.4536 - acc: 0.819 - ETA: 0s - loss: 0.4564 - acc: 0.816 - ETA: 0s - loss: 0.4481 - acc: 0.817 - ETA: 0s - loss: 0.4368 - acc: 0.829 - ETA: 0s - loss: 0.4422 - acc: 0.822 - ETA: 0s - loss: 0.4473 - acc: 0.817 - ETA: 0s - loss: 0.4566 - acc: 0.811 - ETA: 0s - loss: 0.4600 - acc: 0.810 - 1s 833us/step - loss: 0.4676 - acc: 0.8056 - val_loss: 0.4397 - val_acc: 0.8098\n",
      "Epoch 12/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1808 - acc: 1.000 - ETA: 0s - loss: 0.4300 - acc: 0.842 - ETA: 0s - loss: 0.4504 - acc: 0.815 - ETA: 0s - loss: 0.4561 - acc: 0.819 - ETA: 0s - loss: 0.4979 - acc: 0.794 - ETA: 0s - loss: 0.5029 - acc: 0.791 - ETA: 0s - loss: 0.4980 - acc: 0.796 - ETA: 0s - loss: 0.4777 - acc: 0.805 - ETA: 0s - loss: 0.4588 - acc: 0.816 - ETA: 0s - loss: 0.4579 - acc: 0.817 - ETA: 0s - loss: 0.4551 - acc: 0.819 - ETA: 0s - loss: 0.4574 - acc: 0.817 - ETA: 0s - loss: 0.4617 - acc: 0.813 - 1s 1ms/step - loss: 0.4732 - acc: 0.8056 - val_loss: 0.4403 - val_acc: 0.8098\n",
      "Epoch 13/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.8093 - acc: 0.500 - ETA: 0s - loss: 0.4856 - acc: 0.806 - ETA: 0s - loss: 0.4501 - acc: 0.824 - ETA: 0s - loss: 0.4529 - acc: 0.816 - ETA: 0s - loss: 0.4355 - acc: 0.830 - ETA: 0s - loss: 0.4583 - acc: 0.813 - ETA: 0s - loss: 0.4655 - acc: 0.810 - ETA: 0s - loss: 0.4642 - acc: 0.810 - ETA: 0s - loss: 0.4607 - acc: 0.819 - ETA: 0s - loss: 0.4599 - acc: 0.820 - ETA: 0s - loss: 0.4550 - acc: 0.822 - ETA: 0s - loss: 0.4564 - acc: 0.819 - ETA: 0s - loss: 0.4592 - acc: 0.815 - ETA: 0s - loss: 0.4684 - acc: 0.808 - 1s 1ms/step - loss: 0.4728 - acc: 0.8056 - val_loss: 0.4351 - val_acc: 0.8098\n",
      "Epoch 14/20\n",
      "648/648 [==============================] - ETA: 1s - loss: 0.8708 - acc: 0.500 - ETA: 1s - loss: 0.4917 - acc: 0.800 - ETA: 1s - loss: 0.4645 - acc: 0.816 - ETA: 0s - loss: 0.4662 - acc: 0.815 - ETA: 0s - loss: 0.4630 - acc: 0.817 - ETA: 0s - loss: 0.4613 - acc: 0.822 - ETA: 0s - loss: 0.4938 - acc: 0.798 - ETA: 0s - loss: 0.4906 - acc: 0.800 - ETA: 0s - loss: 0.4935 - acc: 0.799 - ETA: 0s - loss: 0.4866 - acc: 0.801 - ETA: 0s - loss: 0.4893 - acc: 0.801 - ETA: 0s - loss: 0.4752 - acc: 0.809 - ETA: 0s - loss: 0.4766 - acc: 0.805 - ETA: 0s - loss: 0.4778 - acc: 0.806 - ETA: 0s - loss: 0.4748 - acc: 0.808 - ETA: 0s - loss: 0.4731 - acc: 0.810 - ETA: 0s - loss: 0.4800 - acc: 0.802 - ETA: 0s - loss: 0.4719 - acc: 0.808 - ETA: 0s - loss: 0.4715 - acc: 0.808 - 1s 2ms/step - loss: 0.4754 - acc: 0.8056 - val_loss: 0.4267 - val_acc: 0.8098\n",
      "Epoch 15/20\n",
      "648/648 [==============================] - ETA: 1s - loss: 0.3109 - acc: 1.000 - ETA: 0s - loss: 0.3541 - acc: 0.861 - ETA: 0s - loss: 0.4349 - acc: 0.803 - ETA: 0s - loss: 0.4554 - acc: 0.785 - ETA: 0s - loss: 0.4087 - acc: 0.823 - ETA: 0s - loss: 0.4458 - acc: 0.797 - ETA: 0s - loss: 0.4381 - acc: 0.810 - ETA: 0s - loss: 0.4336 - acc: 0.816 - ETA: 0s - loss: 0.4284 - acc: 0.820 - ETA: 0s - loss: 0.4336 - acc: 0.817 - ETA: 0s - loss: 0.4384 - acc: 0.818 - ETA: 0s - loss: 0.4311 - acc: 0.825 - ETA: 0s - loss: 0.4565 - acc: 0.809 - ETA: 0s - loss: 0.4539 - acc: 0.814 - ETA: 0s - loss: 0.4660 - acc: 0.804 - ETA: 0s - loss: 0.4677 - acc: 0.803 - ETA: 0s - loss: 0.4705 - acc: 0.801 - ETA: 0s - loss: 0.4673 - acc: 0.804 - ETA: 0s - loss: 0.4648 - acc: 0.804 - ETA: 0s - loss: 0.4665 - acc: 0.801 - 1s 2ms/step - loss: 0.4615 - acc: 0.8056 - val_loss: 0.4253 - val_acc: 0.8098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2591 - acc: 1.000 - ETA: 0s - loss: 0.3943 - acc: 0.891 - ETA: 0s - loss: 0.3620 - acc: 0.885 - ETA: 0s - loss: 0.3465 - acc: 0.888 - ETA: 0s - loss: 0.3825 - acc: 0.862 - ETA: 0s - loss: 0.4066 - acc: 0.847 - ETA: 0s - loss: 0.4047 - acc: 0.851 - ETA: 0s - loss: 0.4051 - acc: 0.849 - ETA: 0s - loss: 0.4107 - acc: 0.841 - ETA: 0s - loss: 0.4108 - acc: 0.842 - ETA: 0s - loss: 0.4240 - acc: 0.835 - ETA: 0s - loss: 0.4133 - acc: 0.843 - ETA: 0s - loss: 0.4258 - acc: 0.836 - ETA: 0s - loss: 0.4330 - acc: 0.833 - ETA: 0s - loss: 0.4348 - acc: 0.828 - ETA: 0s - loss: 0.4381 - acc: 0.825 - ETA: 0s - loss: 0.4462 - acc: 0.814 - ETA: 0s - loss: 0.4532 - acc: 0.808 - ETA: 0s - loss: 0.4531 - acc: 0.808 - ETA: 0s - loss: 0.4540 - acc: 0.807 - ETA: 0s - loss: 0.4588 - acc: 0.805 - 1s 2ms/step - loss: 0.4584 - acc: 0.8056 - val_loss: 0.4306 - val_acc: 0.8098\n",
      "Epoch 17/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.1405 - acc: 1.000 - ETA: 1s - loss: 0.3350 - acc: 0.884 - ETA: 1s - loss: 0.3123 - acc: 0.913 - ETA: 1s - loss: 0.3449 - acc: 0.902 - ETA: 1s - loss: 0.3529 - acc: 0.900 - ETA: 0s - loss: 0.3473 - acc: 0.898 - ETA: 0s - loss: 0.3747 - acc: 0.875 - ETA: 0s - loss: 0.3856 - acc: 0.868 - ETA: 0s - loss: 0.4149 - acc: 0.852 - ETA: 0s - loss: 0.4138 - acc: 0.849 - ETA: 0s - loss: 0.4356 - acc: 0.828 - ETA: 0s - loss: 0.4400 - acc: 0.828 - ETA: 0s - loss: 0.4401 - acc: 0.828 - ETA: 0s - loss: 0.4383 - acc: 0.830 - ETA: 0s - loss: 0.4399 - acc: 0.831 - ETA: 0s - loss: 0.4459 - acc: 0.827 - ETA: 0s - loss: 0.4491 - acc: 0.823 - ETA: 0s - loss: 0.4503 - acc: 0.820 - ETA: 0s - loss: 0.4483 - acc: 0.819 - ETA: 0s - loss: 0.4494 - acc: 0.818 - ETA: 0s - loss: 0.4486 - acc: 0.818 - ETA: 0s - loss: 0.4541 - acc: 0.815 - ETA: 0s - loss: 0.4643 - acc: 0.806 - 1s 2ms/step - loss: 0.4653 - acc: 0.8056 - val_loss: 0.4336 - val_acc: 0.8098\n",
      "Epoch 18/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.2473 - acc: 1.000 - ETA: 0s - loss: 0.5197 - acc: 0.736 - ETA: 0s - loss: 0.5115 - acc: 0.763 - ETA: 0s - loss: 0.5019 - acc: 0.766 - ETA: 0s - loss: 0.4998 - acc: 0.767 - ETA: 0s - loss: 0.4838 - acc: 0.787 - ETA: 0s - loss: 0.4824 - acc: 0.785 - ETA: 0s - loss: 0.4817 - acc: 0.787 - ETA: 0s - loss: 0.4860 - acc: 0.785 - ETA: 0s - loss: 0.4700 - acc: 0.799 - ETA: 0s - loss: 0.4717 - acc: 0.795 - ETA: 0s - loss: 0.4692 - acc: 0.798 - ETA: 0s - loss: 0.4701 - acc: 0.798 - ETA: 0s - loss: 0.4734 - acc: 0.796 - ETA: 0s - loss: 0.4648 - acc: 0.801 - ETA: 0s - loss: 0.4599 - acc: 0.804 - ETA: 0s - loss: 0.4633 - acc: 0.804 - 1s 1ms/step - loss: 0.4628 - acc: 0.8056 - val_loss: 0.4158 - val_acc: 0.8098\n",
      "Epoch 19/20\n",
      "648/648 [==============================] - ETA: 1s - loss: 0.9027 - acc: 0.500 - ETA: 1s - loss: 0.3912 - acc: 0.794 - ETA: 0s - loss: 0.3594 - acc: 0.833 - ETA: 0s - loss: 0.3944 - acc: 0.820 - ETA: 0s - loss: 0.4289 - acc: 0.810 - ETA: 0s - loss: 0.3981 - acc: 0.837 - ETA: 0s - loss: 0.4277 - acc: 0.828 - ETA: 0s - loss: 0.4351 - acc: 0.824 - ETA: 0s - loss: 0.4310 - acc: 0.825 - ETA: 0s - loss: 0.4461 - acc: 0.815 - ETA: 0s - loss: 0.4463 - acc: 0.815 - ETA: 0s - loss: 0.4543 - acc: 0.806 - ETA: 0s - loss: 0.4598 - acc: 0.803 - ETA: 0s - loss: 0.4567 - acc: 0.805 - ETA: 0s - loss: 0.4483 - acc: 0.810 - ETA: 0s - loss: 0.4515 - acc: 0.807 - 1s 1ms/step - loss: 0.4517 - acc: 0.8056 - val_loss: 0.4136 - val_acc: 0.8098\n",
      "Epoch 20/20\n",
      "648/648 [==============================] - ETA: 0s - loss: 0.0835 - acc: 1.000 - ETA: 0s - loss: 0.4758 - acc: 0.789 - ETA: 0s - loss: 0.4671 - acc: 0.800 - ETA: 0s - loss: 0.4356 - acc: 0.812 - ETA: 0s - loss: 0.4445 - acc: 0.811 - ETA: 0s - loss: 0.4748 - acc: 0.788 - ETA: 0s - loss: 0.4986 - acc: 0.791 - ETA: 0s - loss: 0.4990 - acc: 0.791 - ETA: 0s - loss: 0.5042 - acc: 0.783 - ETA: 0s - loss: 0.4974 - acc: 0.788 - ETA: 0s - loss: 0.4907 - acc: 0.792 - ETA: 0s - loss: 0.4841 - acc: 0.800 - ETA: 0s - loss: 0.4802 - acc: 0.798 - ETA: 0s - loss: 0.4828 - acc: 0.796 - ETA: 0s - loss: 0.4775 - acc: 0.801 - ETA: 0s - loss: 0.4782 - acc: 0.798 - ETA: 0s - loss: 0.4721 - acc: 0.800 - ETA: 0s - loss: 0.4664 - acc: 0.802 - ETA: 0s - loss: 0.4661 - acc: 0.805 - 1s 2ms/step - loss: 0.4644 - acc: 0.8056 - val_loss: 0.4126 - val_acc: 0.8098\n",
      "Test Loss:  0.41255556056104553\n",
      "Test Accuracy 0.8098159509202454\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_history  = model.fit(X_train, Y_train, batch_size=2, epochs=20\n",
    "                          ,validation_data=(X_test, Y_test))\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "#print(metrics.accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=3)\n",
    "print('Test Loss: ', score[0])\n",
    "print('Test Accuracy', score[1])\n",
    "\n",
    "\n",
    "# list all data in history\n",
    "print(train_history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(train_history.history['acc'])\n",
    "plt.plot(train_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='uniform', input_shape=(4,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu',kernel_initializer='uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "    model.summary()\n",
    "    model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "\n",
    "model = KerasClassifier(build_fn=build_classifier, batch_size = 4, epochs=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracies = cross_val_score(estimator=model,X= X_train, y=Y_train, cv= 4, n_jobs=-1 )\n",
    "#mean = accuracies.mean()\n",
    "#variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88877934],\n",
       "       [0.8750973 ],\n",
       "       [0.84641385],\n",
       "       [0.80985576],\n",
       "       [0.864495  ],\n",
       "       [0.8592342 ],\n",
       "       [0.8871237 ],\n",
       "       [0.8648539 ],\n",
       "       [0.93668646],\n",
       "       [0.82678396],\n",
       "       [0.89186573],\n",
       "       [0.86755735],\n",
       "       [0.83479303],\n",
       "       [0.6682531 ],\n",
       "       [0.84212995],\n",
       "       [0.8453222 ],\n",
       "       [0.877563  ],\n",
       "       [0.8791875 ],\n",
       "       [0.91492194],\n",
       "       [0.88435036],\n",
       "       [0.8911291 ],\n",
       "       [0.81004703],\n",
       "       [0.8770675 ],\n",
       "       [0.94639087],\n",
       "       [0.68446714],\n",
       "       [0.88786453],\n",
       "       [0.8339741 ],\n",
       "       [0.88763493],\n",
       "       [0.8915693 ],\n",
       "       [0.9325823 ],\n",
       "       [0.8963032 ],\n",
       "       [0.8886853 ],\n",
       "       [0.8540376 ],\n",
       "       [0.83389586],\n",
       "       [0.8634942 ],\n",
       "       [0.7222165 ],\n",
       "       [0.94080406],\n",
       "       [0.9190327 ],\n",
       "       [0.8487348 ],\n",
       "       [0.7540104 ],\n",
       "       [0.8795369 ],\n",
       "       [0.81267524],\n",
       "       [0.88310975],\n",
       "       [0.8814483 ],\n",
       "       [0.90399665],\n",
       "       [0.8813172 ],\n",
       "       [0.8418993 ],\n",
       "       [0.8767992 ],\n",
       "       [0.93657374],\n",
       "       [0.9373149 ],\n",
       "       [0.8332395 ],\n",
       "       [0.8677277 ],\n",
       "       [0.88971776],\n",
       "       [0.8641188 ],\n",
       "       [0.83842313],\n",
       "       [0.88391066],\n",
       "       [0.8680627 ],\n",
       "       [0.8414091 ],\n",
       "       [0.8590497 ],\n",
       "       [0.87846404],\n",
       "       [0.93720573],\n",
       "       [0.892877  ],\n",
       "       [0.60090345],\n",
       "       [0.87118524],\n",
       "       [0.86185485],\n",
       "       [0.7858895 ],\n",
       "       [0.80163527],\n",
       "       [0.89487374],\n",
       "       [0.736497  ],\n",
       "       [0.69904894],\n",
       "       [0.85231364],\n",
       "       [0.7726982 ],\n",
       "       [0.86384857],\n",
       "       [0.86194646],\n",
       "       [0.8883868 ],\n",
       "       [0.8949693 ],\n",
       "       [0.88287365],\n",
       "       [0.8407507 ],\n",
       "       [0.8847005 ],\n",
       "       [0.92160034],\n",
       "       [0.84840924],\n",
       "       [0.7387993 ],\n",
       "       [0.9144193 ],\n",
       "       [0.80779815],\n",
       "       [0.8488406 ],\n",
       "       [0.5983413 ],\n",
       "       [0.73647803],\n",
       "       [0.84518814],\n",
       "       [0.91074175],\n",
       "       [0.5654049 ],\n",
       "       [0.9044693 ],\n",
       "       [0.7462399 ],\n",
       "       [0.76474005],\n",
       "       [0.90077156],\n",
       "       [0.8577345 ],\n",
       "       [0.5748764 ],\n",
       "       [0.870264  ],\n",
       "       [0.8985569 ],\n",
       "       [0.90119755],\n",
       "       [0.876365  ],\n",
       "       [0.83514845],\n",
       "       [0.54531187],\n",
       "       [0.9358696 ],\n",
       "       [0.90077126],\n",
       "       [0.86352193],\n",
       "       [0.62614167],\n",
       "       [0.58309233],\n",
       "       [0.8455137 ],\n",
       "       [0.79553336],\n",
       "       [0.8716365 ],\n",
       "       [0.825425  ],\n",
       "       [0.8081584 ],\n",
       "       [0.86624557],\n",
       "       [0.91951656],\n",
       "       [0.8786214 ],\n",
       "       [0.82097936],\n",
       "       [0.5618205 ],\n",
       "       [0.88169134],\n",
       "       [0.85627925],\n",
       "       [0.852509  ],\n",
       "       [0.76334035],\n",
       "       [0.88329065],\n",
       "       [0.8217157 ],\n",
       "       [0.85171014],\n",
       "       [0.76776373],\n",
       "       [0.8780196 ],\n",
       "       [0.92935055],\n",
       "       [0.8614115 ],\n",
       "       [0.8611924 ],\n",
       "       [0.88466513],\n",
       "       [0.9101285 ],\n",
       "       [0.8705702 ],\n",
       "       [0.8719209 ],\n",
       "       [0.9073947 ],\n",
       "       [0.8075901 ],\n",
       "       [0.82486546],\n",
       "       [0.8707776 ],\n",
       "       [0.89258146],\n",
       "       [0.802782  ],\n",
       "       [0.5846758 ],\n",
       "       [0.6242015 ],\n",
       "       [0.58590174],\n",
       "       [0.7930793 ],\n",
       "       [0.8925032 ],\n",
       "       [0.81146586],\n",
       "       [0.8861165 ],\n",
       "       [0.89750093],\n",
       "       [0.8649771 ],\n",
       "       [0.83455265],\n",
       "       [0.8641623 ],\n",
       "       [0.6280114 ],\n",
       "       [0.93986076],\n",
       "       [0.8622808 ],\n",
       "       [0.5531214 ],\n",
       "       [0.8840438 ],\n",
       "       [0.8828825 ],\n",
       "       [0.63798046],\n",
       "       [0.873333  ],\n",
       "       [0.9277179 ],\n",
       "       [0.8561588 ],\n",
       "       [0.7881933 ],\n",
       "       [0.6098371 ],\n",
       "       [0.8400853 ]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import adam\n",
    "\n",
    "model_tune = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                64        \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:479: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 2,402\n",
      "Trainable params: 2,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_tune.add(Dense(32, activation='relu', kernel_initializer='uniform', input_shape=(4,)))\n",
    "model_tune.add(Dropout(0.15))\n",
    "model_tune.add(Dense(32, activation='relu',kernel_initializer='uniform'))\n",
    "model_tune.add(Dropout(0.1))\n",
    "model_tune.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n",
    "\n",
    "model_tune.summary()\n",
    "\n",
    "model_tune.compile(optimizer=adam(lr=0.00001), loss= 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 518 samples, validate on 130 samples\n",
      "Epoch 1/15\n",
      "518/518 [==============================] - ETA: 2:15 - loss: 0.6932 - acc: 0.250 - ETA: 4s - loss: 0.6931 - acc: 0.5800  - ETA: 1s - loss: 0.6931 - acc: 0.671 - ETA: 0s - loss: 0.6931 - acc: 0.716 - ETA: 0s - loss: 0.6930 - acc: 0.732 - ETA: 0s - loss: 0.6930 - acc: 0.752 - 1s 3ms/step - loss: 0.6930 - acc: 0.7529 - val_loss: 0.6927 - val_acc: 0.8308\n",
      "Epoch 2/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.500 - ETA: 0s - loss: 0.6928 - acc: 0.721 - ETA: 0s - loss: 0.6928 - acc: 0.740 - ETA: 0s - loss: 0.6927 - acc: 0.746 - ETA: 0s - loss: 0.6926 - acc: 0.785 - ETA: 0s - loss: 0.6926 - acc: 0.792 - 0s 570us/step - loss: 0.6925 - acc: 0.7992 - val_loss: 0.6922 - val_acc: 0.8308\n",
      "Epoch 3/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6931 - acc: 0.500 - ETA: 0s - loss: 0.6923 - acc: 0.800 - ETA: 0s - loss: 0.6922 - acc: 0.810 - ETA: 0s - loss: 0.6921 - acc: 0.813 - ETA: 0s - loss: 0.6921 - acc: 0.798 - ETA: 0s - loss: 0.6921 - acc: 0.796 - 0s 626us/step - loss: 0.6920 - acc: 0.7992 - val_loss: 0.6916 - val_acc: 0.8308\n",
      "Epoch 4/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6920 - acc: 0.750 - ETA: 0s - loss: 0.6915 - acc: 0.842 - ETA: 0s - loss: 0.6915 - acc: 0.830 - ETA: 0s - loss: 0.6917 - acc: 0.793 - ETA: 0s - loss: 0.6916 - acc: 0.802 - ETA: 0s - loss: 0.6915 - acc: 0.799 - 0s 570us/step - loss: 0.6915 - acc: 0.7992 - val_loss: 0.6911 - val_acc: 0.8308\n",
      "Epoch 5/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6900 - acc: 1.000 - ETA: 0s - loss: 0.6917 - acc: 0.722 - ETA: 0s - loss: 0.6912 - acc: 0.787 - ETA: 0s - loss: 0.6913 - acc: 0.778 - ETA: 0s - loss: 0.6911 - acc: 0.797 - 0s 503us/step - loss: 0.6910 - acc: 0.7992 - val_loss: 0.6905 - val_acc: 0.8308\n",
      "Epoch 6/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6910 - acc: 0.750 - ETA: 0s - loss: 0.6908 - acc: 0.781 - ETA: 0s - loss: 0.6907 - acc: 0.785 - ETA: 0s - loss: 0.6905 - acc: 0.804 - ETA: 0s - loss: 0.6904 - acc: 0.809 - ETA: 0s - loss: 0.6904 - acc: 0.800 - 0s 576us/step - loss: 0.6904 - acc: 0.7992 - val_loss: 0.6898 - val_acc: 0.8308\n",
      "Epoch 7/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6882 - acc: 1.000 - ETA: 0s - loss: 0.6897 - acc: 0.833 - ETA: 0s - loss: 0.6901 - acc: 0.797 - ETA: 0s - loss: 0.6900 - acc: 0.796 - ETA: 0s - loss: 0.6898 - acc: 0.808 - 0s 510us/step - loss: 0.6899 - acc: 0.7992 - val_loss: 0.6892 - val_acc: 0.8308\n",
      "Epoch 8/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6874 - acc: 1.000 - ETA: 0s - loss: 0.6892 - acc: 0.822 - ETA: 0s - loss: 0.6889 - acc: 0.840 - ETA: 0s - loss: 0.6891 - acc: 0.816 - ETA: 0s - loss: 0.6892 - acc: 0.806 - ETA: 0s - loss: 0.6892 - acc: 0.802 - 0s 558us/step - loss: 0.6893 - acc: 0.7992 - val_loss: 0.6885 - val_acc: 0.8308\n",
      "Epoch 9/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6896 - acc: 0.750 - ETA: 0s - loss: 0.6892 - acc: 0.777 - ETA: 0s - loss: 0.6888 - acc: 0.800 - ETA: 0s - loss: 0.6889 - acc: 0.792 - ETA: 0s - loss: 0.6888 - acc: 0.795 - ETA: 0s - loss: 0.6886 - acc: 0.802 - 0s 581us/step - loss: 0.6886 - acc: 0.7992 - val_loss: 0.6878 - val_acc: 0.8308\n",
      "Epoch 10/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6935 - acc: 0.500 - ETA: 0s - loss: 0.6884 - acc: 0.788 - ETA: 0s - loss: 0.6881 - acc: 0.798 - ETA: 0s - loss: 0.6882 - acc: 0.788 - ETA: 0s - loss: 0.6881 - acc: 0.791 - ETA: 0s - loss: 0.6879 - acc: 0.803 - 0s 595us/step - loss: 0.6879 - acc: 0.7992 - val_loss: 0.6870 - val_acc: 0.8308\n",
      "Epoch 11/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6978 - acc: 0.250 - ETA: 0s - loss: 0.6879 - acc: 0.775 - ETA: 0s - loss: 0.6877 - acc: 0.781 - ETA: 0s - loss: 0.6873 - acc: 0.801 - ETA: 0s - loss: 0.6871 - acc: 0.808 - 0s 537us/step - loss: 0.6872 - acc: 0.7992 - val_loss: 0.6862 - val_acc: 0.8308\n",
      "Epoch 12/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6880 - acc: 0.750 - ETA: 0s - loss: 0.6863 - acc: 0.822 - ETA: 0s - loss: 0.6868 - acc: 0.796 - ETA: 0s - loss: 0.6864 - acc: 0.811 - ETA: 0s - loss: 0.6865 - acc: 0.803 - ETA: 0s - loss: 0.6865 - acc: 0.799 - 0s 568us/step - loss: 0.6865 - acc: 0.7992 - val_loss: 0.6854 - val_acc: 0.8308\n",
      "Epoch 13/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6866 - acc: 0.750 - ETA: 0s - loss: 0.6864 - acc: 0.777 - ETA: 0s - loss: 0.6856 - acc: 0.811 - ETA: 0s - loss: 0.6854 - acc: 0.818 - ETA: 0s - loss: 0.6857 - acc: 0.802 - ETA: 0s - loss: 0.6856 - acc: 0.801 - 0s 566us/step - loss: 0.6857 - acc: 0.7992 - val_loss: 0.6845 - val_acc: 0.8308\n",
      "Epoch 14/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6801 - acc: 1.000 - ETA: 0s - loss: 0.6851 - acc: 0.805 - ETA: 0s - loss: 0.6842 - acc: 0.836 - ETA: 0s - loss: 0.6842 - acc: 0.833 - ETA: 0s - loss: 0.6847 - acc: 0.811 - ETA: 0s - loss: 0.6849 - acc: 0.802 - 0s 614us/step - loss: 0.6850 - acc: 0.7992 - val_loss: 0.6836 - val_acc: 0.8308\n",
      "Epoch 15/15\n",
      "518/518 [==============================] - ETA: 0s - loss: 0.6778 - acc: 1.000 - ETA: 0s - loss: 0.6837 - acc: 0.820 - ETA: 0s - loss: 0.6850 - acc: 0.774 - ETA: 0s - loss: 0.6850 - acc: 0.773 - ETA: 0s - loss: 0.6847 - acc: 0.783 - ETA: 0s - loss: 0.6845 - acc: 0.787 - ETA: 0s - loss: 0.6843 - acc: 0.793 - 0s 780us/step - loss: 0.6841 - acc: 0.7992 - val_loss: 0.6827 - val_acc: 0.8308\n",
      "Test Loss:  0.6833624390005334\n",
      "Test Accuracy 0.8098159509202454\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_hist  = model_tune.fit(X_train, Y_train, batch_size=4, epochs=15\n",
    "                          ,validation_split=0.2)\n",
    "\n",
    "#Y_predicted = model.predict(X_test)\n",
    "\n",
    "#print(metrics.accuracy_score(Y_test, Y_predicted))\n",
    "\n",
    "score = model_tune.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test Loss: ', score[0])\n",
    "print('Test Accuracy', score[1])\n",
    "\n",
    "\n",
    "# list all data in history\n",
    "print(train_hist.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(train_hist.history['acc'])\n",
    "plt.plot(train_hist.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(train_hist.history['loss'])\n",
    "plt.plot(train_hist.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class = model_tune.predict_classes(X_test)\n",
    "y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  31],\n",
       "       [  0, 132]], dtype=int64)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(Y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0,0.5,'Positive'), Text(0,1.5,'Negative')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax= plt.subplot()\n",
    "#cm = classification_report(y_test, y_pred_lstm)\n",
    "sns.heatmap(confusion_matrix(Y_test, y_pred_class), annot=True, ax = ax, fmt='g'); #annot=True to annotate cells\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Negative', 'Positive'])\n",
    "ax.yaxis.set_ticklabels(['Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "#from tpot import TPOTRegressor\n",
    "\n",
    "tpot = TPOTClassifier(generations=5,verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8009970667380429\n",
      "Generation 2 - Current best internal CV score: 0.8009970667380429\n",
      "Generation 3 - Current best internal CV score: 0.8009970667380429\n",
      "Generation 4 - Current best internal CV score: 0.8009970667380429\n",
      "Generation 5 - Current best internal CV score: 0.8009970667380429\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.8500000000000001, min_samples_leaf=19, min_samples_split=11, n_estimators=100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=False, early_stop=None, generations=5,\n",
       "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=100,\n",
       "        random_state=None, scoring=None, subsample=1.0, use_dask=False,\n",
       "        verbosity=2, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('extratreesclassifier', ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "           max_depth=None, max_features=0.8500000000000001,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=19,\n",
       "           min_samples_split=11, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.fitted_pipeline_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best pipeline as per TPOT is the below - \n",
    "\n",
    "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=90, p=1, weights=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8226600985221675"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot.score(X_test,\n",
    "           Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = tpot.predict(X_test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot.export('tpot_Edgar_Sentiments.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using H2O.ai API  to find the best model - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode)\n",
      "  Starting server from C:\\Users\\nikhi\\Anaconda3\\lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\nikhi\\AppData\\Local\\Temp\\tmp3fvl92bt\n",
      "  JVM stdout: C:\\Users\\nikhi\\AppData\\Local\\Temp\\tmp3fvl92bt\\h2o_nikhi_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\nikhi\\AppData\\Local\\Temp\\tmp3fvl92bt\\h2o_nikhi_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 1 day </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_nikhi_dvh1lf</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.523 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  -------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.2\n",
       "H2O cluster version age:    2 months and 1 day\n",
       "H2O cluster name:           H2O_from_python_nikhi_dvh1lf\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.523 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.5 final\n",
       "--------------------------  -------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df.to_csv('final_label_json_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th><th style=\"text-align: right;\">  azure_api_score</th><th style=\"text-align: right;\">  google_sentiment_socre</th><th style=\"text-align: right;\">  ibm_score</th><th style=\"text-align: right;\">  amazon_sentiment_score</th><th style=\"text-align: right;\">  sentiment</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">         0.978328</td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.816136</td><td style=\"text-align: right;\">                0.750581</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.558518</td><td style=\"text-align: right;\">                0.880566</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                    -0.3</td><td style=\"text-align: right;\">  -0.598559</td><td style=\"text-align: right;\">                0.953385</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">         0.905933</td><td style=\"text-align: right;\">                     0.5</td><td style=\"text-align: right;\">   0.790615</td><td style=\"text-align: right;\">                0.977495</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">         0.904133</td><td style=\"text-align: right;\">                     0  </td><td style=\"text-align: right;\">   0.988573</td><td style=\"text-align: right;\">                0.674756</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   6</td><td style=\"text-align: right;\">         0.832192</td><td style=\"text-align: right;\">                     0.1</td><td style=\"text-align: right;\">   0.574769</td><td style=\"text-align: right;\">                0.373289</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.4</td><td style=\"text-align: right;\">   0.884016</td><td style=\"text-align: right;\">                0.717327</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   9</td><td style=\"text-align: right;\">         0.74868 </td><td style=\"text-align: right;\">                     0.6</td><td style=\"text-align: right;\">   0.59894 </td><td style=\"text-align: right;\">                0.637107</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\">         0.952201</td><td style=\"text-align: right;\">                     0.4</td><td style=\"text-align: right;\">   0.875206</td><td style=\"text-align: right;\">                0.945111</td><td style=\"text-align: right;\">          1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  12</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.569009</td><td style=\"text-align: right;\">                0.638542</td><td style=\"text-align: right;\">          0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = h2o.import_file('final_label_json_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:811\n",
      "Cols:6\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>C1                </th><th>azure_api_score    </th><th>google_sentiment_socre  </th><th>ibm_score         </th><th>amazon_sentiment_score  </th><th>sentiment          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>real               </td><td>real                    </td><td>real              </td><td>real                    </td><td>int                </td></tr>\n",
       "<tr><td>mins   </td><td>0.0               </td><td>0.0621877611       </td><td>-0.6999999881           </td><td>-0.897554         </td><td>0.2974953949            </td><td>0.0                </td></tr>\n",
       "<tr><td>mean   </td><td>828.5326757090012 </td><td>0.6427028278373615 </td><td>0.21418002826979035     </td><td>0.5957383181257702</td><td>0.7602460733112212      </td><td>0.8064118372379778 </td></tr>\n",
       "<tr><td>maxs   </td><td>1642.0            </td><td>0.9968479276       </td><td>0.8999999762            </td><td>0.998674          </td><td>0.9985154271            </td><td>1.0                </td></tr>\n",
       "<tr><td>sigma  </td><td>455.07252153575007</td><td>0.22324971364639776</td><td>0.24069582961015862     </td><td>0.4168205697793954</td><td>0.17980453185630274     </td><td>0.39535366015815204</td></tr>\n",
       "<tr><td>zeros  </td><td>1                 </td><td>0                  </td><td>187                     </td><td>18                </td><td>0                       </td><td>157                </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                  </td><td>0                       </td><td>0                 </td><td>0                       </td><td>0                  </td></tr>\n",
       "<tr><td>0      </td><td>0.0               </td><td>0.9783278108       </td><td>0.200000003             </td><td>0.816136          </td><td>0.7505810857            </td><td>1.0                </td></tr>\n",
       "<tr><td>1      </td><td>1.0               </td><td>0.5                </td><td>0.200000003             </td><td>0.558518          </td><td>0.8805660009            </td><td>1.0                </td></tr>\n",
       "<tr><td>2      </td><td>3.0               </td><td>0.5                </td><td>-0.3000000119           </td><td>-0.598559         </td><td>0.9533853531            </td><td>0.0                </td></tr>\n",
       "<tr><td>3      </td><td>4.0               </td><td>0.9059334397       </td><td>0.5                     </td><td>0.790615          </td><td>0.9774951339            </td><td>0.0                </td></tr>\n",
       "<tr><td>4      </td><td>5.0               </td><td>0.9041327238       </td><td>0.0                     </td><td>0.988573          </td><td>0.6747556925            </td><td>1.0                </td></tr>\n",
       "<tr><td>5      </td><td>6.0               </td><td>0.8321921229       </td><td>0.1000000015            </td><td>0.574769          </td><td>0.3732891977            </td><td>0.0                </td></tr>\n",
       "<tr><td>6      </td><td>8.0               </td><td>0.5                </td><td>0.400000006             </td><td>0.884016          </td><td>0.7173274755            </td><td>1.0                </td></tr>\n",
       "<tr><td>7      </td><td>9.0               </td><td>0.7486802936       </td><td>0.6000000238            </td><td>0.59894           </td><td>0.6371069551            </td><td>1.0                </td></tr>\n",
       "<tr><td>8      </td><td>10.0              </td><td>0.9522012472       </td><td>0.400000006             </td><td>0.875206          </td><td>0.9451110363            </td><td>1.0                </td></tr>\n",
       "<tr><td>9      </td><td>12.0              </td><td>0.5                </td><td>0.200000003             </td><td>0.569009          </td><td>0.6385424137            </td><td>0.0                </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  C1</th><th style=\"text-align: right;\">  azure_api_score</th><th style=\"text-align: right;\">  google_sentiment_socre</th><th style=\"text-align: right;\">  ibm_score</th><th style=\"text-align: right;\">  amazon_sentiment_score</th><th style=\"text-align: right;\">  sentiment</th><th style=\"text-align: right;\">  target</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   0</td><td style=\"text-align: right;\">         0.978328</td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.816136</td><td style=\"text-align: right;\">                0.750581</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   1</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.558518</td><td style=\"text-align: right;\">                0.880566</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                    -0.3</td><td style=\"text-align: right;\">  -0.598559</td><td style=\"text-align: right;\">                0.953385</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">         0.905933</td><td style=\"text-align: right;\">                     0.5</td><td style=\"text-align: right;\">   0.790615</td><td style=\"text-align: right;\">                0.977495</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   5</td><td style=\"text-align: right;\">         0.904133</td><td style=\"text-align: right;\">                     0  </td><td style=\"text-align: right;\">   0.988573</td><td style=\"text-align: right;\">                0.674756</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   6</td><td style=\"text-align: right;\">         0.832192</td><td style=\"text-align: right;\">                     0.1</td><td style=\"text-align: right;\">   0.574769</td><td style=\"text-align: right;\">                0.373289</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.4</td><td style=\"text-align: right;\">   0.884016</td><td style=\"text-align: right;\">                0.717327</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">   9</td><td style=\"text-align: right;\">         0.74868 </td><td style=\"text-align: right;\">                     0.6</td><td style=\"text-align: right;\">   0.59894 </td><td style=\"text-align: right;\">                0.637107</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  10</td><td style=\"text-align: right;\">         0.952201</td><td style=\"text-align: right;\">                     0.4</td><td style=\"text-align: right;\">   0.875206</td><td style=\"text-align: right;\">                0.945111</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">       1</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  12</td><td style=\"text-align: right;\">         0.5     </td><td style=\"text-align: right;\">                     0.2</td><td style=\"text-align: right;\">   0.569009</td><td style=\"text-align: right;\">                0.638542</td><td style=\"text-align: right;\">          0</td><td style=\"text-align: right;\">       0</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df['sentiment'].asfactor()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:811\n",
      "Cols:7\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>C1                </th><th>azure_api_score    </th><th>google_sentiment_socre  </th><th>ibm_score         </th><th>amazon_sentiment_score  </th><th>sentiment          </th><th>target  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int               </td><td>real               </td><td>real                    </td><td>real              </td><td>real                    </td><td>int                </td><td>enum    </td></tr>\n",
       "<tr><td>mins   </td><td>0.0               </td><td>0.0621877611       </td><td>-0.6999999881           </td><td>-0.897554         </td><td>0.2974953949            </td><td>0.0                </td><td>        </td></tr>\n",
       "<tr><td>mean   </td><td>828.5326757090012 </td><td>0.6427028278373615 </td><td>0.21418002826979035     </td><td>0.5957383181257702</td><td>0.7602460733112212      </td><td>0.8064118372379778 </td><td>        </td></tr>\n",
       "<tr><td>maxs   </td><td>1642.0            </td><td>0.9968479276       </td><td>0.8999999762            </td><td>0.998674          </td><td>0.9985154271            </td><td>1.0                </td><td>        </td></tr>\n",
       "<tr><td>sigma  </td><td>455.07252153575007</td><td>0.22324971364639776</td><td>0.24069582961015862     </td><td>0.4168205697793954</td><td>0.17980453185630274     </td><td>0.39535366015815204</td><td>        </td></tr>\n",
       "<tr><td>zeros  </td><td>1                 </td><td>0                  </td><td>187                     </td><td>18                </td><td>0                       </td><td>157                </td><td>        </td></tr>\n",
       "<tr><td>missing</td><td>0                 </td><td>0                  </td><td>0                       </td><td>0                 </td><td>0                       </td><td>0                  </td><td>0       </td></tr>\n",
       "<tr><td>0      </td><td>0.0               </td><td>0.9783278108       </td><td>0.200000003             </td><td>0.816136          </td><td>0.7505810857            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>1      </td><td>1.0               </td><td>0.5                </td><td>0.200000003             </td><td>0.558518          </td><td>0.8805660009            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>2      </td><td>3.0               </td><td>0.5                </td><td>-0.3000000119           </td><td>-0.598559         </td><td>0.9533853531            </td><td>0.0                </td><td>0       </td></tr>\n",
       "<tr><td>3      </td><td>4.0               </td><td>0.9059334397       </td><td>0.5                     </td><td>0.790615          </td><td>0.9774951339            </td><td>0.0                </td><td>0       </td></tr>\n",
       "<tr><td>4      </td><td>5.0               </td><td>0.9041327238       </td><td>0.0                     </td><td>0.988573          </td><td>0.6747556925            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>5      </td><td>6.0               </td><td>0.8321921229       </td><td>0.1000000015            </td><td>0.574769          </td><td>0.3732891977            </td><td>0.0                </td><td>0       </td></tr>\n",
       "<tr><td>6      </td><td>8.0               </td><td>0.5                </td><td>0.400000006             </td><td>0.884016          </td><td>0.7173274755            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>7      </td><td>9.0               </td><td>0.7486802936       </td><td>0.6000000238            </td><td>0.59894           </td><td>0.6371069551            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>8      </td><td>10.0              </td><td>0.9522012472       </td><td>0.400000006             </td><td>0.875206          </td><td>0.9451110363            </td><td>1.0                </td><td>1       </td></tr>\n",
       "<tr><td>9      </td><td>12.0              </td><td>0.5                </td><td>0.200000003             </td><td>0.569009          </td><td>0.6385424137            </td><td>0.0                </td><td>0       </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"target\"\n",
    "x = features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "aml = H2OAutoML(max_models = 10, max_runtime_secs=120, seed = 1)\n",
    "aml.train(x = x, y = y, training_frame= df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>GLM_grid_1_AutoML_20190320_200417_model_1          </td><td style=\"text-align: right;\">0.742136</td><td style=\"text-align: right;\"> 0.438973</td><td style=\"text-align: right;\">              0.4679  </td><td style=\"text-align: right;\">0.373468</td><td style=\"text-align: right;\">0.139478</td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190320_200417                       </td><td style=\"text-align: right;\">0.740748</td><td style=\"text-align: right;\"> 0.427411</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.367227</td><td style=\"text-align: right;\">0.134855</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190320_200417</td><td style=\"text-align: right;\">0.737724</td><td style=\"text-align: right;\"> 0.430725</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.36908 </td><td style=\"text-align: right;\">0.13622 </td></tr>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190320_200417   </td><td style=\"text-align: right;\">0.736516</td><td style=\"text-align: right;\"> 0.43116 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.369314</td><td style=\"text-align: right;\">0.136393</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190320_200417                       </td><td style=\"text-align: right;\">0.723509</td><td style=\"text-align: right;\"> 0.453431</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.380405</td><td style=\"text-align: right;\">0.144708</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190320_200417_model_1          </td><td style=\"text-align: right;\">0.723383</td><td style=\"text-align: right;\"> 0.488385</td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.393917</td><td style=\"text-align: right;\">0.155171</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190320_200417                       </td><td style=\"text-align: right;\">0.72145 </td><td style=\"text-align: right;\"> 0.455546</td><td style=\"text-align: right;\">              0.487135</td><td style=\"text-align: right;\">0.379813</td><td style=\"text-align: right;\">0.144258</td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190320_200417                       </td><td style=\"text-align: right;\">0.716015</td><td style=\"text-align: right;\"> 0.462293</td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.38265 </td><td style=\"text-align: right;\">0.146421</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190320_200417              </td><td style=\"text-align: right;\">0.714544</td><td style=\"text-align: right;\"> 0.464378</td><td style=\"text-align: right;\">              0.496815</td><td style=\"text-align: right;\">0.387359</td><td style=\"text-align: right;\">0.150047</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190320_200417                       </td><td style=\"text-align: right;\">0.708935</td><td style=\"text-align: right;\"> 0.47874 </td><td style=\"text-align: right;\">              0.5     </td><td style=\"text-align: right;\">0.389983</td><td style=\"text-align: right;\">0.152087</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head()\n",
    "#lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#y_pred_h2o = aml.predict(X_test)\n",
    "df1 =h2o.H2OFrame(X_test)\n",
    "#y_pred_h2o = aml.predict(X_test)\n",
    "#y_pred_h2o\n",
    "#y_pred_h2o = h2o.deeplearning(x, y, training_frame = train, validation_frame = valid,)\n",
    "#h2o.confusionMatrix(y_pred_h2o, valid = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  azure_api_score</th><th style=\"text-align: right;\">  google_sentiment_socre</th><th style=\"text-align: right;\">  ibm_score</th><th style=\"text-align: right;\">  amazon_sentiment_score</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.6875</td><td style=\"text-align: right;\">   0.898289</td><td style=\"text-align: right;\">               0.611774 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.625 </td><td style=\"text-align: right;\">   0.876083</td><td style=\"text-align: right;\">               0.443459 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.705929</td><td style=\"text-align: right;\">                  0.5625</td><td style=\"text-align: right;\">   0.751259</td><td style=\"text-align: right;\">               0.0525138</td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.4375</td><td style=\"text-align: right;\">   0.797158</td><td style=\"text-align: right;\">               0.690586 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.5625</td><td style=\"text-align: right;\">   0.905007</td><td style=\"text-align: right;\">               0.828573 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.5625</td><td style=\"text-align: right;\">   0.888162</td><td style=\"text-align: right;\">               0.944919 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.625 </td><td style=\"text-align: right;\">   0.937871</td><td style=\"text-align: right;\">               0.461272 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.468419</td><td style=\"text-align: right;\">                  0.6875</td><td style=\"text-align: right;\">   0.789764</td><td style=\"text-align: right;\">               0.771942 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.947612</td><td style=\"text-align: right;\">                  0.9375</td><td style=\"text-align: right;\">   0.950588</td><td style=\"text-align: right;\">               0.963662 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">         0.747647</td><td style=\"text-align: right;\">                  0.4375</td><td style=\"text-align: right;\">   0.809732</td><td style=\"text-align: right;\">               0.525685 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0591668</td><td style=\"text-align: right;\">0.940833</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0715695</td><td style=\"text-align: right;\">0.928431</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.102093 </td><td style=\"text-align: right;\">0.897907</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0987179</td><td style=\"text-align: right;\">0.901282</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0680783</td><td style=\"text-align: right;\">0.931922</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0665929</td><td style=\"text-align: right;\">0.933407</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0667654</td><td style=\"text-align: right;\">0.933235</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0626903</td><td style=\"text-align: right;\">0.93731 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0310117</td><td style=\"text-align: right;\">0.968988</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.101915 </td><td style=\"text-align: right;\">0.898085</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_h2o = aml.predict(df1)\n",
    "y_pred_h2o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
